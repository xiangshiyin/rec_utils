{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the NCF module under folder [cf_ec2](../cf_ec2) with ml-1m dataset, save the best model (using integrated modules with compile and fit components, with gmf and mlp pretrain)\n",
    "\n",
    "#### 4/20/2020, test with original paper's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import (\n",
    "    Adam,\n",
    "    Adamax,\n",
    "    Adagrad,\n",
    "    SGD,\n",
    "    RMSprop\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, \n",
    "    Input,\n",
    "    Flatten, \n",
    "    Multiply, \n",
    "    Concatenate,\n",
    "    Dense\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cf_ec2 import (\n",
    "    GMF,\n",
    "    MLP,\n",
    "    NCF,\n",
    "    Data,\n",
    "    evaluation,\n",
    "    evaluation_grouped\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check original paper's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../metadata/original_dataset/\u001b[00m\r\n",
      "├── item_input\r\n",
      "├── labels\r\n",
      "├── testNegatives\r\n",
      "├── testRatings\r\n",
      "├── train\r\n",
      "└── user_input\r\n",
      "\r\n",
      "0 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ../metadata/original_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metadata/original_dataset/train','rb') as fp:\n",
    "    train = pickle.load(fp, encoding='latin1')\n",
    "with open('../metadata/original_dataset/testRatings','rb') as fp:\n",
    "    testRatings = pickle.load(fp, encoding='latin1')\n",
    "with open('../metadata/original_dataset/testNegatives','rb') as fp:\n",
    "    testNegatives = pickle.load(fp, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.dok.dok_matrix, list, list)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train), type(testRatings), type(testNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 25], [1, 133], [2, 207], [3, 208], [4, 222]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRatings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 6040)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testRatings), len(testNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metadata/original_dataset/user_input','rb') as fp:\n",
    "    user_input = pickle.load(fp, encoding='latin1')\n",
    "with open('../metadata/original_dataset/item_input','rb') as fp:\n",
    "    item_input = pickle.load(fp, encoding='latin1')\n",
    "with open('../metadata/original_dataset/labels','rb') as fp:\n",
    "    labels = pickle.load(fp, encoding='latin1')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, list)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_input), type(item_input), type(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reformat the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [0, 25] //[1064, 174, 2791, 3373, 269]\n",
      "1: [1, 133] //[1072, 3154, 3368, 3644, 549]\n",
      "2: [2, 207] //[2216, 209, 2347, 3, 1652]\n",
      "3: [3, 208] //[3023, 1489, 1916, 1706, 1221]\n",
      "4: [4, 222] //[1794, 3535, 108, 593, 466]\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(testRatings):\n",
    "    if idx<5:\n",
    "        print('{}: {} //{}'.format(idx,value, testNegatives[idx][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 ms, sys: 16 ms, total: 44.4 ms\n",
      "Wall time: 43.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_test, item_test, labels_test = [],[],[]\n",
    "for idx in range(len(testRatings)):\n",
    "    user_test.extend(\n",
    "        [testRatings[idx][0]]*(len(testNegatives[idx])+1)\n",
    "    )\n",
    "    item_test.append(testRatings[idx][1])\n",
    "    item_test.extend(testNegatives[idx])\n",
    "    labels_test.append(1)\n",
    "    labels_test.extend([0]*len(testNegatives[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: create the model architecture and fit model with dataset from original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_items = train.shape\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_users = num_users\n",
    "n_items = num_items\n",
    "n_factors_gmf = 8\n",
    "layers_mlp = [64,32,16,8]\n",
    "# n_factors_gmf = 4\n",
    "# layers_mlp = [16,8,4]\n",
    "reg_gmf = 0.\n",
    "reg_layers_mlp = [0.,0.,0.,0.]\n",
    "learning_rate = 0.001\n",
    "flg_pretrain = ''\n",
    "filepath = ''\n",
    "filepath_mlp_pretrain = ''\n",
    "filepath_mlp_pretrain = ''\n",
    "num_epochs = 20\n",
    "batch_size = 256\n",
    "\n",
    "ncf = NCF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    n_factors_gmf=n_factors_gmf,\n",
    "    layers_mlp=layers_mlp,\n",
    "    reg_gmf=reg_gmf,\n",
    "    reg_layers_mlp=reg_layers_mlp\n",
    ")\n",
    "ncf.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.compile(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mlp_User (Embedding)  (None, 1, 32)        193280      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mlp_Item (Embedding)  (None, 1, 32)        118592      item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_mlp_User (Flatten)      (None, 32)           0           embedding_mlp_User[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_mlp_Item (Flatten)      (None, 32)           0           embedding_mlp_Item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concat_mlp_UserItem (Concatenat (None, 64)           0           flatten_mlp_User[0][0]           \n",
      "                                                                 flatten_mlp_Item[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_gmf_User (Embedding)  (None, 1, 8)         48320       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_gmf_Item (Embedding)  (None, 1, 8)         29648       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_1 (Dense)             (None, 32)           2080        concat_mlp_UserItem[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_gmf_User (Flatten)      (None, 8)            0           embedding_gmf_User[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_gmf_Item (Flatten)      (None, 8)            0           embedding_gmf_Item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_2 (Dense)             (None, 16)           528         mlp_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_gmf_UserItem (Multiply (None, 8)            0           flatten_gmf_User[0][0]           \n",
      "                                                                 flatten_gmf_Item[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_3 (Dense)             (None, 8)            136         mlp_layer_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat_gmf_mlp (Concatenate)    (None, 16)           0           multiply_gmf_UserItem[0][0]      \n",
      "                                                                 mlp_layer_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            17          concat_gmf_mlp[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 392,601\n",
      "Trainable params: 392,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ncf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4970845 samples, validate on 604000 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16958, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf-weights-improvement-01-0.1696.hdf5\n",
      "4970845/4970845 - 57s - loss: 0.3219 - accuracy: 0.8570 - val_loss: 0.1696 - val_accuracy: 0.9391\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16958 to 0.15503, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf-weights-improvement-02-0.1550.hdf5\n",
      "4970845/4970845 - 56s - loss: 0.2744 - accuracy: 0.8802 - val_loss: 0.1550 - val_accuracy: 0.9410\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15503 to 0.15225, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf-weights-improvement-03-0.1523.hdf5\n",
      "4970845/4970845 - 53s - loss: 0.2627 - accuracy: 0.8858 - val_loss: 0.1523 - val_accuracy: 0.9412\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15225 to 0.14039, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf-weights-improvement-04-0.1404.hdf5\n",
      "4970845/4970845 - 53s - loss: 0.2559 - accuracy: 0.8892 - val_loss: 0.1404 - val_accuracy: 0.9454\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 53s - loss: 0.2508 - accuracy: 0.8917 - val_loss: 0.1588 - val_accuracy: 0.9372\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 55s - loss: 0.2466 - accuracy: 0.8940 - val_loss: 0.1514 - val_accuracy: 0.9405\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 53s - loss: 0.2430 - accuracy: 0.8957 - val_loss: 0.1471 - val_accuracy: 0.9424\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14039\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "4970845/4970845 - 54s - loss: 0.2397 - accuracy: 0.8973 - val_loss: 0.1455 - val_accuracy: 0.9443\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 53s - loss: 0.2273 - accuracy: 0.9036 - val_loss: 0.1502 - val_accuracy: 0.9404\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 54s - loss: 0.2242 - accuracy: 0.9052 - val_loss: 0.1587 - val_accuracy: 0.9367\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 54s - loss: 0.2225 - accuracy: 0.9060 - val_loss: 0.1585 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.14039\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "4970845/4970845 - 57s - loss: 0.2212 - accuracy: 0.9068 - val_loss: 0.1449 - val_accuracy: 0.9430\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 54s - loss: 0.2157 - accuracy: 0.9095 - val_loss: 0.1523 - val_accuracy: 0.9401\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 53s - loss: 0.2150 - accuracy: 0.9098 - val_loss: 0.1524 - val_accuracy: 0.9400\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14039\n",
      "4970845/4970845 - 51s - loss: 0.2144 - accuracy: 0.9102 - val_loss: 0.1508 - val_accuracy: 0.9405\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.14039\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "4970845/4970845 - 52s - loss: 0.2140 - accuracy: 0.9104 - val_loss: 0.1566 - val_accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "# def fit(self, dataset, \n",
    "batch_size=256\n",
    "num_epochs=20\n",
    "path_model_weights='/Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf-weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "path_csvlog='/Users/xyin/Documents/work/projects/rec_utils/metadata/ncf4/ncf_log.csv'\n",
    "\n",
    "## create the callback metrics\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath= path_model_weights, \n",
    "    monitor='val_loss',\n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "csvlog = tf.keras.callbacks.CSVLogger(\n",
    "    filename=path_csvlog, \n",
    "    separator=',', \n",
    "    append=False\n",
    ")\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(patience=12)\n",
    "lrreduce = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", \n",
    "    factor=0.3, \n",
    "    patience=4, \n",
    "    verbose=1\n",
    ")  \n",
    "metrics2 = evaluation_grouped.metricsCallback(batch_size=batch_size,log_steps=100)      \n",
    "## fit the model\n",
    "hist = ncf.model.fit(\n",
    "    x = [\n",
    "        np.array(user_input),\n",
    "        np.array(item_input)\n",
    "    ],\n",
    "    y = np.array(labels),\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    "    callbacks=[metrics2,checkpoint,csvlog,earlystop,lrreduce],\n",
    "    validation_data=(\n",
    "        [\n",
    "            np.array(user_test),\n",
    "            np.array(item_test)\n",
    "        ],\n",
    "        np.array(labels_test)\n",
    "    )\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to load the parameters from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.model.load_weights('../metadata/ncf4/ncf-weights-improvement-04-0.1404.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 2.44 s, total: 19.2 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "scores = ncf.model.evaluate(\n",
    "    x = [\n",
    "        np.array(user_test),\n",
    "        np.array(item_test)\n",
    "    ],\n",
    "    y = np.array(labels_test),\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14038968149246955, 0.945404]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.model.save('../metadata/ncf4/ncf-best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.models.load_model('../metadata/ncf4/ncf-best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [09:03<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 20s, sys: 1min 22s, total: 12min 43s\n",
      "Wall time: 9min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2016294613947125, 0.8940297085975318, 0.1403896816127934)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "evaluator = evaluation_grouped.metricsEval(\n",
    "    model=model4,\n",
    "    users=user_input,\n",
    "    items=item_input\n",
    ")\n",
    "evaluator.getRecs()\n",
    "rmse,auc,logloss = evaluator.getOverlapBasedMetrics(\n",
    "    user_test,\n",
    "    item_test,\n",
    "    labels_test\n",
    ")\n",
    "rmse,auc,logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.7 s, sys: 8.58 s, total: 59.3 s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.029635761589403974,\n",
       " 0.002963576158940397,\n",
       " 0.013684980463253551,\n",
       " 0.008958596131609377)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recall,precision,ndcg,map2 = evaluator.getRankBasedMetrics(\n",
    "    user_test,\n",
    "    item_test,\n",
    "    labels_test\n",
    ")\n",
    "recall,precision,ndcg,map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metrics are still one order lower than reported numbers in the paper. Although loss function value is close to reported one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "## original paper's model output\n",
    "(base) xyin self/neural_collaborative_filtering [09:14:12]$ docker run --volume=$(pwd):/home ncf-keras-theano python NeuMF.py --dataset ml-1m --epochs 20 --batch_size 256 --num_factors 8 --layers [64,32,16,8] --reg_mf 0 --reg_layers [0,0,0,0] --num_neg 4 --lr 0.001 --learner adam --verbose 1 --out 1\n",
    "Using Theano backend.\n",
    "NeuMF arguments: Namespace(batch_size=256, dataset='ml-1m', epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0,0,0,0]', reg_mf=0.0, verbose=1)\n",
    "Load data done [20.3 s]. #user=6040, #item=3706, #train=994169, #test=6040\n",
    "Init: HR = 0.0957, NDCG = 0.0448\n",
    "Iteration 0 [106.5 s]: HR = 0.6000, NDCG = 0.3403, loss = 0.3170 [4.2 s]\n",
    "Iteration 1 [78.4 s]: HR = 0.6421, NDCG = 0.3704, loss = 0.2743 [3.7 s]\n",
    "Iteration 2 [79.2 s]: HR = 0.6591, NDCG = 0.3832, loss = 0.2635 [3.6 s]\n",
    "Iteration 3 [69.0 s]: HR = 0.6608, NDCG = 0.3865, loss = 0.2579 [3.6 s]\n",
    "Iteration 4 [69.0 s]: HR = 0.6689, NDCG = 0.3948, loss = 0.2537 [3.6 s]\n",
    "Iteration 5 [69.8 s]: HR = 0.6685, NDCG = 0.3929, loss = 0.2507 [3.6 s]\n",
    "Iteration 6 [68.5 s]: HR = 0.6785, NDCG = 0.4003, loss = 0.2480 [3.6 s]\n",
    "Iteration 7 [81.2 s]: HR = 0.6743, NDCG = 0.3992, loss = 0.2458 [3.6 s]\n",
    "Iteration 8 [74.9 s]: HR = 0.6765, NDCG = 0.4013, loss = 0.2435 [3.6 s]\n",
    "Iteration 9 [75.7 s]: HR = 0.6791, NDCG = 0.4042, loss = 0.2414 [3.7 s]\n",
    "Iteration 10 [76.2 s]: HR = 0.6755, NDCG = 0.4040, loss = 0.2399 [3.9 s]\n",
    "Iteration 11 [434.2 s]: HR = 0.6849, NDCG = 0.4100, loss = 0.2379 [4.0 s]\n",
    "Iteration 12 [79.7 s]: HR = 0.6815, NDCG = 0.4098, loss = 0.2363 [3.6 s]\n",
    "Iteration 13 [78.7 s]: HR = 0.6781, NDCG = 0.4059, loss = 0.2352 [3.6 s]\n",
    "Iteration 14 [69.5 s]: HR = 0.6854, NDCG = 0.4078, loss = 0.2338 [3.6 s]\n",
    "Iteration 15 [67.5 s]: HR = 0.6815, NDCG = 0.4110, loss = 0.2328 [3.6 s]\n",
    "Iteration 16 [68.4 s]: HR = 0.6848, NDCG = 0.4089, loss = 0.2316 [3.6 s]\n",
    "Iteration 17 [67.2 s]: HR = 0.6831, NDCG = 0.4098, loss = 0.2305 [3.6 s]\n",
    "Iteration 18 [78.4 s]: HR = 0.6849, NDCG = 0.4088, loss = 0.2300 [3.6 s]\n",
    "Iteration 19 [75.2 s]: HR = 0.6846, NDCG = 0.4076, loss = 0.2287 [3.6 s]\n",
    "End. Best Iteration 14:  HR = 0.6854, NDCG = 0.4078.\n",
    "The best NeuMF model is saved to Pretrain/ml-1m_NeuMF_8_[64,32,16,8]_1587302095.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### probably our defined evluation modules have issues???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.836016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.831106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.874568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.967178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.959833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.221819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.798001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.899354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.919642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  prediction\n",
       "0        0       0    0.883521\n",
       "1        0       1    0.731152\n",
       "2        0       2    0.721472\n",
       "3        0       3    0.819745\n",
       "4        0       4    0.836016\n",
       "5        0       5    0.933966\n",
       "6        0       6    0.117248\n",
       "7        0       7    0.831106\n",
       "8        0       8    0.874568\n",
       "9        0       9    0.967178\n",
       "10       0      10    0.959833\n",
       "11       0      11    0.221819\n",
       "12       0      12    0.798001\n",
       "13       0      13    0.899354\n",
       "14       0      14    0.919642"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.all_predictions.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: borrow the original paper's evaluation logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get topK predictions for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 958 ms, total: 11.2 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10\n",
    "topKItems = evaluator.all_predictions.groupby('userID',as_index=False)\\\n",
    "    .apply(lambda items: items.nlargest(k,'prediction'))\\\n",
    "        .reset_index(drop=True)\n",
    "## append rank\n",
    "topKItems['rnk'] = topKItems.groupby('userID',sort=False).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "      <th>rnk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.990228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.988341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0.974924</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>0.974696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>0.973926</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0.970118</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0.968304</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.967178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0.966618</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.964157</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.992387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.986484</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0.985492</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0.981105</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>0.978150</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.977716</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0.976713</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1528</td>\n",
       "      <td>0.976070</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.975028</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>0.982188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>711</td>\n",
       "      <td>0.981694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  prediction  rnk\n",
       "0        0      26    0.990228    1\n",
       "1        0      40    0.988341    2\n",
       "2        0     167    0.974924    3\n",
       "3        0     390    0.974696    4\n",
       "4        0     381    0.973926    5\n",
       "5        0     104    0.970118    6\n",
       "6        0     280    0.968304    7\n",
       "7        0       9    0.967178    8\n",
       "8        0     124    0.966618    9\n",
       "9        0      22    0.964157   10\n",
       "10       1      78    0.992387    1\n",
       "11       1      90    0.988180    2\n",
       "12       1     150    0.986484    3\n",
       "13       1     123    0.985492    4\n",
       "14       1     151    0.981105    5\n",
       "15       1     264    0.978150    6\n",
       "16       1      48    0.977716    7\n",
       "17       1     124    0.976713    8\n",
       "18       1    1528    0.976070    9\n",
       "19       1      23    0.975028   10\n",
       "20       2     127    0.982188    1\n",
       "21       2     711    0.981694    2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topKItems.head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0], [25, 1064, 174, 2791, 3373], [1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test[:5], item_test[:5], labels_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0       0      25       1\n",
       "1       1     133       1\n",
       "2       2     207       1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_true = pd.DataFrame({\n",
    "    'userID':user_test,\n",
    "    'itemID':item_test,\n",
    "    'rating':labels_test\n",
    "})\n",
    "rating_true = rating_true[rating_true.rating>0].reset_index(drop=True)\n",
    "rating_true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.990228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0.974924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       0      26    0.990228\n",
       "1       0      40    0.988341\n",
       "2       0     167    0.974924"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_pred = topKItems.loc[:,topKItems.columns[:3]].copy()\n",
    "rating_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 3.15 ms, total: 14.3 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "overlap = pd.merge(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    on=['userID','itemID']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029635761589403974"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap.shape[0]/n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the original paper didn't use allUser-allItem combinations as the basis of hitRate and NDCG evaluation. Instead, it uses the positive sample in test and 99 negative samples as the basis. Therefore, the hit rate and NDCG are all INFLATED!!\n",
    "#### let's reproduce the author's logic here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get prediction value for the test dataset (1 positive plus 99 negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 25]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRatings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 111 ms, sys: 5.99 ms, total: 117 ms\n",
      "Wall time: 115 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[128, 25, 174, 273, 464, 175, 1064, 1182, 487, 1331]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import heapq\n",
    "idx = 0\n",
    "\n",
    "rating = testRatings[idx]\n",
    "items = testNegatives[idx]\n",
    "u = rating[0]\n",
    "gtItem = rating[1]\n",
    "items.append(gtItem)\n",
    "# Get prediction scores\n",
    "map_item_score = {}\n",
    "users = np.full(len(items), u, dtype = 'int32')\n",
    "predictions = model4.predict([users, np.array(items)], \n",
    "                             batch_size=100, verbose=0)\n",
    "for i in range(len(items)):\n",
    "    item = items[i]\n",
    "    map_item_score[item] = predictions[i]\n",
    "items.pop()\n",
    "\n",
    "# Evaluate top rank list\n",
    "ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)\n",
    "ranklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b831b84d854bfdb97631050d1d34d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 19s, sys: 6.05 s, total: 2min 25s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "## create placeholders for user, item, pred\n",
    "list_users, list_items, list_preds = [], [], []\n",
    "\n",
    "## get predictions for each user-item pair\n",
    "for idx in trange(len(testRatings)):\n",
    "    user = user_test[idx*100:(idx+1)*100]\n",
    "    item = item_test[idx:idx+100]\n",
    "    list_users.extend(user)\n",
    "    list_items.extend(item)\n",
    "    list_preds.extend(\n",
    "        model4.predict(\n",
    "            x=[\n",
    "                np.array(user),\n",
    "                np.array(item)\n",
    "            ]\n",
    "        ).flatten()\n",
    "    )\n",
    "## create a pandas dataframe\n",
    "all_predictions_test = pd.DataFrame(data={\n",
    "    'userID': list_users,\n",
    "    'itemID': list_items,\n",
    "    'prediction': list_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.787151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "      <td>0.399748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.732144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       0      25    0.787151\n",
       "1       0    1064    0.399748\n",
       "2       0     174    0.732144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 171 ms, total: 9.81 s\n",
      "Wall time: 9.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10\n",
    "topKItems_test = all_predictions_test.groupby('userID',as_index=False)\\\n",
    "    .apply(lambda items: items.nlargest(k,'prediction'))\\\n",
    "        .reset_index(drop=True)\n",
    "## append rank\n",
    "topKItems_test['rnk'] = topKItems_test.groupby('userID',sort=False).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "      <th>rnk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.954470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.787151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.732144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction  rnk\n",
       "0       0     128    0.954470    1\n",
       "1       0      25    0.787151    2\n",
       "2       0     174    0.732144    3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topKItems_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0       0      25       1\n",
       "1       1     133       1\n",
       "2       2     207       1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_true = pd.DataFrame({\n",
    "    'userID':user_test,\n",
    "    'itemID':item_test,\n",
    "    'rating':labels_test\n",
    "})\n",
    "rating_true = rating_true[rating_true.rating>0].reset_index(drop=True)\n",
    "rating_true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.954470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.787151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.732144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       0     128    0.954470\n",
       "1       0      25    0.787151\n",
       "2       0     174    0.732144"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_pred = topKItems_test.loc[:,topKItems_test.columns[:3]].copy()\n",
    "rating_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014238410596026487"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap = pd.merge(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    on=['userID','itemID']\n",
    ")\n",
    "(overlap.rating/10).sum()/len(testRatings) #### still much lower than reported number!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try the paper's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from time import time\n",
    "#from numba import jit, autojit\n",
    "\n",
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_testNegatives = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _testNegatives\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _testNegatives = testNegatives\n",
    "    _K = K\n",
    "        \n",
    "    hits, ndcgs = [],[]\n",
    "    if(num_thread > 1): # Multi-thread\n",
    "        pool = multiprocessing.Pool(processes=num_thread)\n",
    "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        hits = [r[0] for r in res]\n",
    "        ndcgs = [r[1] for r in res]\n",
    "        return (hits, ndcgs)\n",
    "    # Single thread\n",
    "    for idx in trange(len(_testRatings)):\n",
    "        (hr,ndcg) = eval_one_rating(idx)\n",
    "        hits.append(hr)\n",
    "        ndcgs.append(ndcg)      \n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    items = _testNegatives[idx]\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    predictions = _model.predict([users, np.array(items)], \n",
    "                                 batch_size=100, verbose=0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20b7c303c1a4a50a1e20e7938c01869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 49s, sys: 3.03 s, total: 1min 52s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hrs,ndcgs = evaluate_model(model4, testRatings, testNegatives, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 1, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6309297535714574,\n",
       " 0.33333333333333337,\n",
       " 0.33333333333333337,\n",
       " 0.6309297535714574,\n",
       " 0,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.2890648263178878,\n",
       " 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcgs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr, ndcg = np.array(hrs).mean(), np.array(ndcgs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6504966887417218"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37691241349812515"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
