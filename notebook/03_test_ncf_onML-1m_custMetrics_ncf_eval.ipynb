{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the NCF module under folder [cf_ec2](../cf_ec2) with ml-1m dataset, save the best model (using integrated modules with compile and fit components, with gmf and mlp pretrain)\n",
    "\n",
    "#### 5/4/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import (\n",
    "    Adam,\n",
    "    Adamax,\n",
    "    Adagrad,\n",
    "    SGD,\n",
    "    RMSprop\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, \n",
    "    Input,\n",
    "    Flatten, \n",
    "    Multiply, \n",
    "    Concatenate,\n",
    "    Dense\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cf_ec2 import (\n",
    "    GMF,\n",
    "    MLP,\n",
    "    NCF,\n",
    "    Data,\n",
    "    evaluation,\n",
    "    evaluation_grouped\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/ml-1m-all-train.csv',sep=',',header=0,names=['user','item','rating','event_ts'])\n",
    "test = pd.read_csv('../data/ml-1m-all-test.csv',sep=',',header=0,names=['user','item','rating','event_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, (250088, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.user.nunique(), test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, (750121, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.user.nunique(), train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>event_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   event_ts\n",
       "0     1  3186     4.0  978300019\n",
       "1     1  1721     4.0  978300055\n",
       "2     1  1270     5.0  978300055"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>event_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1545</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978824139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978824195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>3.0</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   event_ts\n",
       "0     1  1545     4.0  978824139\n",
       "1     1   527     5.0  978824195\n",
       "2     1   745     3.0  978824268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: prepare the data for gmf model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 1.77 s, total: 1min 19s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = Data(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    col_user='user',\n",
    "    col_item='item',\n",
    "    col_rating='rating',\n",
    "    col_time='event_ts',\n",
    "    binary=True,\n",
    "    n_neg=4,\n",
    "    n_neg_test=100,\n",
    "    n_neg_limit=0\n",
    ")\n",
    "dataset.prepTrainDNN(negSample=True)\n",
    "dataset.prepTestDNN(group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item_interacted</th>\n",
       "      <th>item_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>{40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{7, 11, 16, 17, 20, 28, 36, 40, 41, 42, 43, 44...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{130, 131, 132, 133, 134, 135, 136, 9, 137, 13...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                    item_interacted  \\\n",
       "0     0  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1     1  {7, 11, 16, 17, 20, 28, 36, 40, 41, 42, 43, 44...   \n",
       "2     2  {130, 131, 132, 133, 134, 135, 136, 9, 137, 13...   \n",
       "\n",
       "                                       item_negative  \n",
       "0  {40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5...  \n",
       "1  {0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15...  \n",
       "2  {0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.interaction_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newItems = set(dataset.items_test)-set(dataset.items)\n",
    "idx2del = []\n",
    "for idx,item in enumerate(dataset.items_test):\n",
    "    if item in newItems:\n",
    "        idx2del.append(idx)\n",
    "\n",
    "length_test_original = len(dataset.users_test)\n",
    "dataset.users_test = [\n",
    "    dataset.users_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]\n",
    "dataset.items_test = [\n",
    "    dataset.items_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]\n",
    "dataset.ratings_test = [\n",
    "    dataset.ratings_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: create the model architecture and fit model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3660)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.user.nunique(), train.item.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_users = 6040\n",
    "n_items = 3660\n",
    "n_factors_gmf = 8\n",
    "layers_mlp = [64,32,16,8]\n",
    "# n_factors_gmf = 4\n",
    "# layers_mlp = [16,8,4]\n",
    "reg_gmf = 0.\n",
    "reg_layers_mlp = [0.,0.,0.,0.]\n",
    "learning_rate = 0.001\n",
    "flg_pretrain = ''\n",
    "filepath = ''\n",
    "filepath_mlp_pretrain = ''\n",
    "filepath_mlp_pretrain = ''\n",
    "num_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "ncf = NCF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    n_factors_gmf=n_factors_gmf,\n",
    "    layers_mlp=layers_mlp,\n",
    "    reg_gmf=reg_gmf,\n",
    "    reg_layers_mlp=reg_layers_mlp\n",
    ")\n",
    "ncf.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.compile(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mlp_User (Embedding)  (None, 1, 32)        193280      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mlp_Item (Embedding)  (None, 1, 32)        117120      item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_mlp_User (Flatten)      (None, 32)           0           embedding_mlp_User[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_mlp_Item (Flatten)      (None, 32)           0           embedding_mlp_Item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concat_mlp_UserItem (Concatenat (None, 64)           0           flatten_mlp_User[0][0]           \n",
      "                                                                 flatten_mlp_Item[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_gmf_User (Embedding)  (None, 1, 8)         48320       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_gmf_Item (Embedding)  (None, 1, 8)         29280       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_1 (Dense)             (None, 32)           2080        concat_mlp_UserItem[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_gmf_User (Flatten)      (None, 8)            0           embedding_gmf_User[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_gmf_Item (Flatten)      (None, 8)            0           embedding_gmf_Item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_2 (Dense)             (None, 16)           528         mlp_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_gmf_UserItem (Multiply (None, 8)            0           flatten_gmf_User[0][0]           \n",
      "                                                                 flatten_gmf_Item[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mlp_layer_3 (Dense)             (None, 8)            136         mlp_layer_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat_gmf_mlp (Concatenate)    (None, 16)           0           multiply_gmf_UserItem[0][0]      \n",
      "                                                                 mlp_layer_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            17          concat_gmf_mlp[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 390,761\n",
      "Trainable params: 390,761\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ncf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3750605 samples, validate on 25252525 samples\n",
      "Epoch 1/20\n",
      "TimeHistory: 2.48 seconds, 103259.69 examples/second between steps 0 and 500\n",
      "TimeHistory: 1.62 seconds, 157905.65 examples/second between steps 500 and 1000\n",
      "TimeHistory: 1.61 seconds, 159429.32 examples/second between steps 1000 and 1500\n",
      "TimeHistory: 1.64 seconds, 155770.93 examples/second between steps 1500 and 2000\n",
      "TimeHistory: 1.64 seconds, 155922.44 examples/second between steps 2000 and 2500\n",
      "TimeHistory: 1.60 seconds, 160065.15 examples/second between steps 2500 and 3000\n",
      "TimeHistory: 1.64 seconds, 156305.24 examples/second between steps 3000 and 3500\n",
      "TimeHistory: 1.66 seconds, 154308.99 examples/second between steps 3500 and 4000\n",
      "TimeHistory: 1.61 seconds, 158697.51 examples/second between steps 4000 and 4500\n",
      "TimeHistory: 1.66 seconds, 154343.70 examples/second between steps 4500 and 5000\n",
      "TimeHistory: 1.64 seconds, 156344.57 examples/second between steps 5000 and 5500\n",
      "TimeHistory: 1.59 seconds, 161432.12 examples/second between steps 5500 and 6000\n",
      "TimeHistory: 1.62 seconds, 157986.94 examples/second between steps 6000 and 6500\n",
      "TimeHistory: 1.64 seconds, 156504.31 examples/second between steps 6500 and 7000\n",
      "global_steps: 7326, last_log_step: 7000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15619, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-01-0.1562.hdf5\n",
      "3750605/3750605 - 71s - loss: 0.3373 - accuracy: 0.8500 - val_loss: 0.1562 - val_accuracy: 0.9481\n",
      "Epoch 2/20\n",
      "TimeHistory: 47.44 seconds, 5396.79 examples/second between steps 7000 and 7500\n",
      "TimeHistory: 1.48 seconds, 172982.70 examples/second between steps 7500 and 8000\n",
      "TimeHistory: 1.50 seconds, 170206.43 examples/second between steps 8000 and 8500\n",
      "TimeHistory: 1.50 seconds, 170477.34 examples/second between steps 8500 and 9000\n",
      "TimeHistory: 1.71 seconds, 149389.34 examples/second between steps 9000 and 9500\n",
      "TimeHistory: 1.78 seconds, 143905.50 examples/second between steps 9500 and 10000\n",
      "TimeHistory: 1.55 seconds, 165270.18 examples/second between steps 10000 and 10500\n",
      "TimeHistory: 1.69 seconds, 151639.56 examples/second between steps 10500 and 11000\n",
      "TimeHistory: 1.84 seconds, 139338.45 examples/second between steps 11000 and 11500\n",
      "TimeHistory: 1.52 seconds, 168658.06 examples/second between steps 11500 and 12000\n",
      "TimeHistory: 1.81 seconds, 141711.37 examples/second between steps 12000 and 12500\n",
      "TimeHistory: 1.75 seconds, 146514.13 examples/second between steps 12500 and 13000\n",
      "TimeHistory: 1.71 seconds, 149427.36 examples/second between steps 13000 and 13500\n",
      "TimeHistory: 1.54 seconds, 166357.57 examples/second between steps 13500 and 14000\n",
      "TimeHistory: 1.67 seconds, 153013.05 examples/second between steps 14000 and 14500\n",
      "global_steps: 14652, last_log_step: 14500\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15619 to 0.15524, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-02-0.1552.hdf5\n",
      "3750605/3750605 - 69s - loss: 0.2811 - accuracy: 0.8772 - val_loss: 0.1552 - val_accuracy: 0.9440\n",
      "Epoch 3/20\n",
      "TimeHistory: 46.17 seconds, 5545.04 examples/second between steps 14500 and 15000\n",
      "TimeHistory: 1.49 seconds, 171660.43 examples/second between steps 15000 and 15500\n",
      "TimeHistory: 1.56 seconds, 163715.10 examples/second between steps 15500 and 16000\n",
      "TimeHistory: 1.50 seconds, 170222.97 examples/second between steps 16000 and 16500\n",
      "TimeHistory: 1.70 seconds, 150876.24 examples/second between steps 16500 and 17000\n",
      "TimeHistory: 1.59 seconds, 160844.15 examples/second between steps 17000 and 17500\n",
      "TimeHistory: 1.55 seconds, 164712.32 examples/second between steps 17500 and 18000\n",
      "TimeHistory: 1.72 seconds, 148431.37 examples/second between steps 18000 and 18500\n",
      "TimeHistory: 1.92 seconds, 133398.43 examples/second between steps 18500 and 19000\n",
      "TimeHistory: 1.76 seconds, 145592.51 examples/second between steps 19000 and 19500\n",
      "TimeHistory: 2.18 seconds, 117356.75 examples/second between steps 19500 and 20000\n",
      "TimeHistory: 1.93 seconds, 132734.57 examples/second between steps 20000 and 20500\n",
      "TimeHistory: 1.86 seconds, 137477.12 examples/second between steps 20500 and 21000\n",
      "TimeHistory: 1.72 seconds, 149014.47 examples/second between steps 21000 and 21500\n",
      "global_steps: 21978, last_log_step: 21500\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15524 to 0.14497, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-03-0.1450.hdf5\n",
      "3750605/3750605 - 70s - loss: 0.2639 - accuracy: 0.8855 - val_loss: 0.1450 - val_accuracy: 0.9484\n",
      "Epoch 4/20\n",
      "TimeHistory: 46.60 seconds, 5493.52 examples/second between steps 21500 and 22000\n",
      "TimeHistory: 1.63 seconds, 156902.75 examples/second between steps 22000 and 22500\n",
      "TimeHistory: 1.48 seconds, 173116.15 examples/second between steps 22500 and 23000\n",
      "TimeHistory: 1.47 seconds, 173826.51 examples/second between steps 23000 and 23500\n",
      "TimeHistory: 1.82 seconds, 140577.91 examples/second between steps 23500 and 24000\n",
      "TimeHistory: 1.64 seconds, 156118.68 examples/second between steps 24000 and 24500\n",
      "TimeHistory: 1.64 seconds, 156379.04 examples/second between steps 24500 and 25000\n",
      "TimeHistory: 1.73 seconds, 148289.64 examples/second between steps 25000 and 25500\n",
      "TimeHistory: 1.61 seconds, 159208.91 examples/second between steps 25500 and 26000\n",
      "TimeHistory: 1.54 seconds, 166075.77 examples/second between steps 26000 and 26500\n",
      "TimeHistory: 1.52 seconds, 167950.69 examples/second between steps 26500 and 27000\n",
      "TimeHistory: 1.82 seconds, 140957.21 examples/second between steps 27000 and 27500\n",
      "TimeHistory: 1.59 seconds, 160861.11 examples/second between steps 27500 and 28000\n",
      "TimeHistory: 1.55 seconds, 165183.58 examples/second between steps 28000 and 28500\n",
      "TimeHistory: 1.92 seconds, 133574.47 examples/second between steps 28500 and 29000\n",
      "global_steps: 29304, last_log_step: 29000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14497 to 0.14370, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-04-0.1437.hdf5\n",
      "3750605/3750605 - 70s - loss: 0.2543 - accuracy: 0.8901 - val_loss: 0.1437 - val_accuracy: 0.9477\n",
      "Epoch 5/20\n",
      "TimeHistory: 47.28 seconds, 5414.90 examples/second between steps 29000 and 29500\n",
      "TimeHistory: 1.61 seconds, 159039.41 examples/second between steps 29500 and 30000\n",
      "TimeHistory: 1.59 seconds, 160833.12 examples/second between steps 30000 and 30500\n",
      "TimeHistory: 1.57 seconds, 162965.54 examples/second between steps 30500 and 31000\n",
      "TimeHistory: 1.56 seconds, 164264.52 examples/second between steps 31000 and 31500\n",
      "TimeHistory: 1.64 seconds, 155767.59 examples/second between steps 31500 and 32000\n",
      "TimeHistory: 1.95 seconds, 131178.47 examples/second between steps 32000 and 32500\n",
      "TimeHistory: 1.87 seconds, 137112.57 examples/second between steps 32500 and 33000\n",
      "TimeHistory: 1.71 seconds, 149464.78 examples/second between steps 33000 and 33500\n",
      "TimeHistory: 1.93 seconds, 132373.83 examples/second between steps 33500 and 34000\n",
      "TimeHistory: 2.03 seconds, 126358.11 examples/second between steps 34000 and 34500\n",
      "TimeHistory: 1.99 seconds, 128911.54 examples/second between steps 34500 and 35000\n",
      "TimeHistory: 1.86 seconds, 137687.72 examples/second between steps 35000 and 35500\n",
      "TimeHistory: 1.66 seconds, 154366.31 examples/second between steps 35500 and 36000\n",
      "TimeHistory: 2.06 seconds, 124384.93 examples/second between steps 36000 and 36500\n",
      "global_steps: 36630, last_log_step: 36500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14370 to 0.13965, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-05-0.1397.hdf5\n",
      "3750605/3750605 - 72s - loss: 0.2478 - accuracy: 0.8931 - val_loss: 0.1397 - val_accuracy: 0.9476\n",
      "Epoch 6/20\n",
      "TimeHistory: 47.72 seconds, 5364.39 examples/second between steps 36500 and 37000\n",
      "TimeHistory: 1.84 seconds, 139013.09 examples/second between steps 37000 and 37500\n",
      "TimeHistory: 1.73 seconds, 148330.30 examples/second between steps 37500 and 38000\n",
      "TimeHistory: 1.72 seconds, 148742.18 examples/second between steps 38000 and 38500\n",
      "TimeHistory: 1.74 seconds, 147109.77 examples/second between steps 38500 and 39000\n",
      "TimeHistory: 1.67 seconds, 153563.37 examples/second between steps 39000 and 39500\n",
      "TimeHistory: 1.71 seconds, 149535.16 examples/second between steps 39500 and 40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeHistory: 1.74 seconds, 147494.42 examples/second between steps 40000 and 40500\n",
      "TimeHistory: 1.69 seconds, 151247.33 examples/second between steps 40500 and 41000\n",
      "TimeHistory: 1.65 seconds, 154757.22 examples/second between steps 41000 and 41500\n",
      "TimeHistory: 1.74 seconds, 146906.14 examples/second between steps 41500 and 42000\n",
      "TimeHistory: 1.75 seconds, 145968.92 examples/second between steps 42000 and 42500\n",
      "TimeHistory: 1.74 seconds, 146851.41 examples/second between steps 42500 and 43000\n",
      "TimeHistory: 1.70 seconds, 150963.97 examples/second between steps 43000 and 43500\n",
      "global_steps: 43956, last_log_step: 43500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13965\n",
      "3750605/3750605 - 71s - loss: 0.2426 - accuracy: 0.8956 - val_loss: 0.1498 - val_accuracy: 0.9425\n",
      "Epoch 7/20\n",
      "TimeHistory: 46.91 seconds, 5457.81 examples/second between steps 43500 and 44000\n",
      "TimeHistory: 1.53 seconds, 167080.08 examples/second between steps 44000 and 44500\n",
      "TimeHistory: 1.49 seconds, 171610.30 examples/second between steps 44500 and 45000\n",
      "TimeHistory: 1.35 seconds, 189604.50 examples/second between steps 45000 and 45500\n",
      "TimeHistory: 1.33 seconds, 193021.93 examples/second between steps 45500 and 46000\n",
      "TimeHistory: 1.34 seconds, 190497.30 examples/second between steps 46000 and 46500\n",
      "TimeHistory: 1.45 seconds, 176392.14 examples/second between steps 46500 and 47000\n",
      "TimeHistory: 1.58 seconds, 161885.03 examples/second between steps 47000 and 47500\n",
      "TimeHistory: 1.51 seconds, 170004.24 examples/second between steps 47500 and 48000\n",
      "TimeHistory: 1.55 seconds, 164661.14 examples/second between steps 48000 and 48500\n",
      "TimeHistory: 1.53 seconds, 167248.57 examples/second between steps 48500 and 49000\n",
      "TimeHistory: 1.53 seconds, 167314.45 examples/second between steps 49000 and 49500\n",
      "TimeHistory: 1.64 seconds, 156530.78 examples/second between steps 49500 and 50000\n",
      "TimeHistory: 1.76 seconds, 145217.99 examples/second between steps 50000 and 50500\n",
      "TimeHistory: 1.68 seconds, 152292.94 examples/second between steps 50500 and 51000\n",
      "global_steps: 51282, last_log_step: 51000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13965\n",
      "3750605/3750605 - 66s - loss: 0.2381 - accuracy: 0.8977 - val_loss: 0.1452 - val_accuracy: 0.9446\n",
      "Epoch 8/20\n",
      "TimeHistory: 45.21 seconds, 5662.75 examples/second between steps 51000 and 51500\n",
      "TimeHistory: 1.60 seconds, 159667.99 examples/second between steps 51500 and 52000\n",
      "TimeHistory: 1.75 seconds, 146329.37 examples/second between steps 52000 and 52500\n",
      "TimeHistory: 1.76 seconds, 145255.06 examples/second between steps 52500 and 53000\n",
      "TimeHistory: 1.69 seconds, 151890.55 examples/second between steps 53000 and 53500\n",
      "TimeHistory: 1.47 seconds, 173969.78 examples/second between steps 53500 and 54000\n",
      "TimeHistory: 1.42 seconds, 179705.35 examples/second between steps 54000 and 54500\n",
      "TimeHistory: 1.61 seconds, 158777.98 examples/second between steps 54500 and 55000\n",
      "TimeHistory: 1.61 seconds, 158658.45 examples/second between steps 55000 and 55500\n",
      "TimeHistory: 1.74 seconds, 146721.26 examples/second between steps 55500 and 56000\n",
      "TimeHistory: 1.71 seconds, 149950.60 examples/second between steps 56000 and 56500\n",
      "TimeHistory: 1.64 seconds, 155917.76 examples/second between steps 56500 and 57000\n",
      "TimeHistory: 1.68 seconds, 152661.73 examples/second between steps 57000 and 57500\n",
      "TimeHistory: 1.62 seconds, 158262.47 examples/second between steps 57500 and 58000\n",
      "TimeHistory: 1.67 seconds, 152889.97 examples/second between steps 58000 and 58500\n",
      "global_steps: 58608, last_log_step: 58500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13965\n",
      "3750605/3750605 - 70s - loss: 0.2338 - accuracy: 0.8998 - val_loss: 0.1405 - val_accuracy: 0.9464\n",
      "Epoch 9/20\n",
      "TimeHistory: 48.22 seconds, 5308.94 examples/second between steps 58500 and 59000\n",
      "TimeHistory: 2.03 seconds, 125996.16 examples/second between steps 59000 and 59500\n",
      "TimeHistory: 2.09 seconds, 122276.13 examples/second between steps 59500 and 60000\n",
      "TimeHistory: 2.04 seconds, 125325.68 examples/second between steps 60000 and 60500\n",
      "TimeHistory: 1.95 seconds, 131210.85 examples/second between steps 60500 and 61000\n",
      "TimeHistory: 1.70 seconds, 150437.02 examples/second between steps 61000 and 61500\n",
      "TimeHistory: 2.22 seconds, 115523.52 examples/second between steps 61500 and 62000\n",
      "TimeHistory: 2.46 seconds, 104023.01 examples/second between steps 62000 and 62500\n",
      "TimeHistory: 1.96 seconds, 130629.04 examples/second between steps 62500 and 63000\n",
      "TimeHistory: 2.18 seconds, 117287.82 examples/second between steps 63000 and 63500\n",
      "TimeHistory: 2.11 seconds, 121327.83 examples/second between steps 63500 and 64000\n",
      "TimeHistory: 1.81 seconds, 141117.36 examples/second between steps 64000 and 64500\n",
      "TimeHistory: 1.82 seconds, 140347.80 examples/second between steps 64500 and 65000\n",
      "TimeHistory: 1.68 seconds, 152137.34 examples/second between steps 65000 and 65500\n",
      "global_steps: 65934, last_log_step: 65500\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13965 to 0.13823, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-09-0.1382.hdf5\n",
      "3750605/3750605 - 75s - loss: 0.2297 - accuracy: 0.9018 - val_loss: 0.1382 - val_accuracy: 0.9474\n",
      "Epoch 10/20\n",
      "TimeHistory: 47.97 seconds, 5336.28 examples/second between steps 65500 and 66000\n",
      "TimeHistory: 1.63 seconds, 156803.28 examples/second between steps 66000 and 66500\n",
      "TimeHistory: 1.58 seconds, 161608.51 examples/second between steps 66500 and 67000\n",
      "TimeHistory: 1.58 seconds, 162317.80 examples/second between steps 67000 and 67500\n",
      "TimeHistory: 1.58 seconds, 162030.75 examples/second between steps 67500 and 68000\n",
      "TimeHistory: 1.60 seconds, 160227.43 examples/second between steps 68000 and 68500\n",
      "TimeHistory: 1.64 seconds, 156380.39 examples/second between steps 68500 and 69000\n",
      "TimeHistory: 1.58 seconds, 161838.28 examples/second between steps 69000 and 69500\n",
      "TimeHistory: 1.60 seconds, 159632.64 examples/second between steps 69500 and 70000\n",
      "TimeHistory: 1.59 seconds, 161130.34 examples/second between steps 70000 and 70500\n",
      "TimeHistory: 1.61 seconds, 159120.55 examples/second between steps 70500 and 71000\n",
      "TimeHistory: 1.60 seconds, 159975.60 examples/second between steps 71000 and 71500\n",
      "TimeHistory: 1.60 seconds, 159705.32 examples/second between steps 71500 and 72000\n",
      "TimeHistory: 1.59 seconds, 161419.79 examples/second between steps 72000 and 72500\n",
      "TimeHistory: 1.62 seconds, 158390.47 examples/second between steps 72500 and 73000\n",
      "global_steps: 73260, last_log_step: 73000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13823\n",
      "3750605/3750605 - 72s - loss: 0.2260 - accuracy: 0.9036 - val_loss: 0.1435 - val_accuracy: 0.9450\n",
      "Epoch 11/20\n",
      "TimeHistory: 50.50 seconds, 5069.30 examples/second between steps 73000 and 73500\n",
      "TimeHistory: 1.72 seconds, 148539.37 examples/second between steps 73500 and 74000\n",
      "TimeHistory: 1.64 seconds, 155803.91 examples/second between steps 74000 and 74500\n",
      "TimeHistory: 1.65 seconds, 155243.25 examples/second between steps 74500 and 75000\n",
      "TimeHistory: 1.63 seconds, 157494.44 examples/second between steps 75000 and 75500\n",
      "TimeHistory: 1.57 seconds, 162861.48 examples/second between steps 75500 and 76000\n",
      "TimeHistory: 1.57 seconds, 163321.65 examples/second between steps 76000 and 76500\n",
      "TimeHistory: 1.72 seconds, 148508.95 examples/second between steps 76500 and 77000\n",
      "TimeHistory: 1.64 seconds, 156388.02 examples/second between steps 77000 and 77500\n",
      "TimeHistory: 1.56 seconds, 164342.03 examples/second between steps 77500 and 78000\n",
      "TimeHistory: 1.58 seconds, 162491.10 examples/second between steps 78000 and 78500\n",
      "TimeHistory: 1.57 seconds, 162854.44 examples/second between steps 78500 and 79000\n",
      "TimeHistory: 1.50 seconds, 170196.23 examples/second between steps 79000 and 79500\n",
      "TimeHistory: 1.37 seconds, 186796.83 examples/second between steps 79500 and 80000\n",
      "TimeHistory: 1.73 seconds, 147852.09 examples/second between steps 80000 and 80500\n",
      "global_steps: 80586, last_log_step: 80500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13823\n",
      "3750605/3750605 - 72s - loss: 0.2226 - accuracy: 0.9052 - val_loss: 0.1491 - val_accuracy: 0.9424\n",
      "Epoch 12/20\n",
      "TimeHistory: 49.74 seconds, 5146.58 examples/second between steps 80500 and 81000\n",
      "TimeHistory: 1.67 seconds, 153457.08 examples/second between steps 81000 and 81500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeHistory: 1.69 seconds, 151135.79 examples/second between steps 81500 and 82000\n",
      "TimeHistory: 1.52 seconds, 168067.64 examples/second between steps 82000 and 82500\n",
      "TimeHistory: 1.55 seconds, 164972.47 examples/second between steps 82500 and 83000\n",
      "TimeHistory: 1.57 seconds, 163001.69 examples/second between steps 83000 and 83500\n",
      "TimeHistory: 1.38 seconds, 186055.58 examples/second between steps 83500 and 84000\n",
      "TimeHistory: 1.52 seconds, 168034.48 examples/second between steps 84000 and 84500\n",
      "TimeHistory: 1.56 seconds, 163731.25 examples/second between steps 84500 and 85000\n",
      "TimeHistory: 1.54 seconds, 166127.32 examples/second between steps 85000 and 85500\n",
      "TimeHistory: 1.53 seconds, 167563.83 examples/second between steps 85500 and 86000\n",
      "TimeHistory: 1.56 seconds, 164504.41 examples/second between steps 86000 and 86500\n",
      "TimeHistory: 1.54 seconds, 165912.49 examples/second between steps 86500 and 87000\n",
      "TimeHistory: 1.56 seconds, 163987.68 examples/second between steps 87000 and 87500\n",
      "global_steps: 87912, last_log_step: 87500\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.13823 to 0.13289, saving model to /Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-12-0.1329.hdf5\n",
      "3750605/3750605 - 67s - loss: 0.2194 - accuracy: 0.9067 - val_loss: 0.1329 - val_accuracy: 0.9498\n",
      "Epoch 13/20\n",
      "TimeHistory: 45.49 seconds, 5627.07 examples/second between steps 87500 and 88000\n",
      "TimeHistory: 1.65 seconds, 155165.99 examples/second between steps 88000 and 88500\n",
      "TimeHistory: 1.82 seconds, 140514.35 examples/second between steps 88500 and 89000\n",
      "TimeHistory: 1.76 seconds, 145171.13 examples/second between steps 89000 and 89500\n",
      "TimeHistory: 1.72 seconds, 149004.65 examples/second between steps 89500 and 90000\n",
      "TimeHistory: 1.83 seconds, 140017.17 examples/second between steps 90000 and 90500\n",
      "TimeHistory: 1.55 seconds, 165089.91 examples/second between steps 90500 and 91000\n",
      "TimeHistory: 1.60 seconds, 160383.92 examples/second between steps 91000 and 91500\n",
      "TimeHistory: 1.79 seconds, 142669.49 examples/second between steps 91500 and 92000\n",
      "TimeHistory: 2.09 seconds, 122755.82 examples/second between steps 92000 and 92500\n",
      "TimeHistory: 1.84 seconds, 138905.78 examples/second between steps 92500 and 93000\n",
      "TimeHistory: 1.83 seconds, 139762.64 examples/second between steps 93000 and 93500\n",
      "TimeHistory: 1.95 seconds, 131035.90 examples/second between steps 93500 and 94000\n",
      "TimeHistory: 1.51 seconds, 169293.37 examples/second between steps 94000 and 94500\n",
      "TimeHistory: 1.73 seconds, 148321.71 examples/second between steps 94500 and 95000\n",
      "global_steps: 95238, last_log_step: 95000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 73s - loss: 0.2166 - accuracy: 0.9081 - val_loss: 0.1483 - val_accuracy: 0.9422\n",
      "Epoch 14/20\n",
      "TimeHistory: 48.85 seconds, 5240.70 examples/second between steps 95000 and 95500\n",
      "TimeHistory: 1.84 seconds, 138834.96 examples/second between steps 95500 and 96000\n",
      "TimeHistory: 2.20 seconds, 116234.31 examples/second between steps 96000 and 96500\n",
      "TimeHistory: 1.62 seconds, 157563.87 examples/second between steps 96500 and 97000\n",
      "TimeHistory: 1.57 seconds, 162815.69 examples/second between steps 97000 and 97500\n",
      "TimeHistory: 1.61 seconds, 158884.32 examples/second between steps 97500 and 98000\n",
      "TimeHistory: 1.55 seconds, 165556.50 examples/second between steps 98000 and 98500\n",
      "TimeHistory: 1.61 seconds, 158884.41 examples/second between steps 98500 and 99000\n",
      "TimeHistory: 1.88 seconds, 136028.85 examples/second between steps 99000 and 99500\n",
      "TimeHistory: 1.43 seconds, 179325.81 examples/second between steps 99500 and 100000\n",
      "TimeHistory: 1.51 seconds, 169727.50 examples/second between steps 100000 and 100500\n",
      "TimeHistory: 1.54 seconds, 166218.30 examples/second between steps 100500 and 101000\n",
      "TimeHistory: 1.52 seconds, 167872.83 examples/second between steps 101000 and 101500\n",
      "TimeHistory: 1.53 seconds, 166855.58 examples/second between steps 101500 and 102000\n",
      "TimeHistory: 1.54 seconds, 166739.73 examples/second between steps 102000 and 102500\n",
      "global_steps: 102564, last_log_step: 102500\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 71s - loss: 0.2138 - accuracy: 0.9093 - val_loss: 0.1515 - val_accuracy: 0.9418\n",
      "Epoch 15/20\n",
      "TimeHistory: 48.77 seconds, 5249.39 examples/second between steps 102500 and 103000\n",
      "TimeHistory: 2.20 seconds, 116299.51 examples/second between steps 103000 and 103500\n",
      "TimeHistory: 2.11 seconds, 121540.89 examples/second between steps 103500 and 104000\n",
      "TimeHistory: 2.01 seconds, 127551.26 examples/second between steps 104000 and 104500\n",
      "TimeHistory: 2.04 seconds, 125288.45 examples/second between steps 104500 and 105000\n",
      "TimeHistory: 2.28 seconds, 112442.99 examples/second between steps 105000 and 105500\n",
      "TimeHistory: 1.76 seconds, 145398.94 examples/second between steps 105500 and 106000\n",
      "TimeHistory: 1.79 seconds, 142769.84 examples/second between steps 106000 and 106500\n",
      "TimeHistory: 1.59 seconds, 161391.40 examples/second between steps 106500 and 107000\n",
      "TimeHistory: 1.43 seconds, 178633.11 examples/second between steps 107000 and 107500\n",
      "TimeHistory: 1.74 seconds, 147070.57 examples/second between steps 107500 and 108000\n",
      "TimeHistory: 1.65 seconds, 155545.75 examples/second between steps 108000 and 108500\n",
      "TimeHistory: 1.66 seconds, 154672.22 examples/second between steps 108500 and 109000\n",
      "TimeHistory: 1.85 seconds, 138680.63 examples/second between steps 109000 and 109500\n",
      "global_steps: 109890, last_log_step: 109500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 75s - loss: 0.2113 - accuracy: 0.9106 - val_loss: 0.1478 - val_accuracy: 0.9430\n",
      "Epoch 16/20\n",
      "TimeHistory: 49.30 seconds, 5193.18 examples/second between steps 109500 and 110000\n",
      "TimeHistory: 1.63 seconds, 157214.95 examples/second between steps 110000 and 110500\n",
      "TimeHistory: 1.71 seconds, 149541.36 examples/second between steps 110500 and 111000\n",
      "TimeHistory: 1.60 seconds, 159772.03 examples/second between steps 111000 and 111500\n",
      "TimeHistory: 1.61 seconds, 159329.42 examples/second between steps 111500 and 112000\n",
      "TimeHistory: 1.79 seconds, 142659.46 examples/second between steps 112000 and 112500\n",
      "TimeHistory: 1.79 seconds, 142943.92 examples/second between steps 112500 and 113000\n",
      "TimeHistory: 1.68 seconds, 152619.70 examples/second between steps 113000 and 113500\n",
      "TimeHistory: 1.62 seconds, 158020.28 examples/second between steps 113500 and 114000\n",
      "TimeHistory: 1.55 seconds, 165314.96 examples/second between steps 114000 and 114500\n",
      "TimeHistory: 1.62 seconds, 157809.59 examples/second between steps 114500 and 115000\n",
      "TimeHistory: 1.94 seconds, 132236.72 examples/second between steps 115000 and 115500\n",
      "TimeHistory: 1.68 seconds, 152195.52 examples/second between steps 115500 and 116000\n",
      "TimeHistory: 1.60 seconds, 160132.01 examples/second between steps 116000 and 116500\n",
      "TimeHistory: 1.60 seconds, 160447.05 examples/second between steps 116500 and 117000\n",
      "global_steps: 117216, last_log_step: 117000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13289\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "3750605/3750605 - 70s - loss: 0.2090 - accuracy: 0.9117 - val_loss: 0.1475 - val_accuracy: 0.9433\n",
      "Epoch 17/20\n",
      "TimeHistory: 47.21 seconds, 5422.05 examples/second between steps 117000 and 117500\n",
      "TimeHistory: 1.83 seconds, 139749.36 examples/second between steps 117500 and 118000\n",
      "TimeHistory: 1.99 seconds, 128364.02 examples/second between steps 118000 and 118500\n",
      "TimeHistory: 1.88 seconds, 136026.61 examples/second between steps 118500 and 119000\n",
      "TimeHistory: 1.84 seconds, 139491.54 examples/second between steps 119000 and 119500\n",
      "TimeHistory: 1.86 seconds, 137757.28 examples/second between steps 119500 and 120000\n",
      "TimeHistory: 1.80 seconds, 142595.03 examples/second between steps 120000 and 120500\n",
      "TimeHistory: 1.58 seconds, 161730.03 examples/second between steps 120500 and 121000\n",
      "TimeHistory: 1.95 seconds, 131321.39 examples/second between steps 121000 and 121500\n",
      "TimeHistory: 1.72 seconds, 148509.13 examples/second between steps 121500 and 122000\n",
      "TimeHistory: 1.73 seconds, 148103.32 examples/second between steps 122000 and 122500\n",
      "TimeHistory: 1.56 seconds, 164088.23 examples/second between steps 122500 and 123000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeHistory: 1.57 seconds, 163259.34 examples/second between steps 123000 and 123500\n",
      "TimeHistory: 1.69 seconds, 151634.87 examples/second between steps 123500 and 124000\n",
      "TimeHistory: 1.79 seconds, 143013.26 examples/second between steps 124000 and 124500\n",
      "global_steps: 124542, last_log_step: 124500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 73s - loss: 0.1948 - accuracy: 0.9187 - val_loss: 0.1568 - val_accuracy: 0.9391\n",
      "Epoch 18/20\n",
      "TimeHistory: 48.72 seconds, 5254.19 examples/second between steps 124500 and 125000\n",
      "TimeHistory: 1.57 seconds, 163094.71 examples/second between steps 125000 and 125500\n",
      "TimeHistory: 1.73 seconds, 148029.14 examples/second between steps 125500 and 126000\n",
      "TimeHistory: 1.97 seconds, 130026.47 examples/second between steps 126000 and 126500\n",
      "TimeHistory: 1.68 seconds, 152601.15 examples/second between steps 126500 and 127000\n",
      "TimeHistory: 1.91 seconds, 134214.89 examples/second between steps 127000 and 127500\n",
      "TimeHistory: 1.97 seconds, 130081.68 examples/second between steps 127500 and 128000\n",
      "TimeHistory: 1.84 seconds, 139140.86 examples/second between steps 128000 and 128500\n",
      "TimeHistory: 2.04 seconds, 125627.64 examples/second between steps 128500 and 129000\n",
      "TimeHistory: 1.99 seconds, 128469.50 examples/second between steps 129000 and 129500\n",
      "TimeHistory: 1.71 seconds, 150011.04 examples/second between steps 129500 and 130000\n",
      "TimeHistory: 1.83 seconds, 139922.75 examples/second between steps 130000 and 130500\n",
      "TimeHistory: 1.63 seconds, 156830.67 examples/second between steps 130500 and 131000\n",
      "TimeHistory: 1.51 seconds, 169602.35 examples/second between steps 131000 and 131500\n",
      "global_steps: 131868, last_log_step: 131500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 73s - loss: 0.1918 - accuracy: 0.9202 - val_loss: 0.1561 - val_accuracy: 0.9391\n",
      "Epoch 19/20\n",
      "TimeHistory: 48.59 seconds, 5268.07 examples/second between steps 131500 and 132000\n",
      "TimeHistory: 1.52 seconds, 168202.18 examples/second between steps 132000 and 132500\n",
      "TimeHistory: 1.49 seconds, 172252.09 examples/second between steps 132500 and 133000\n",
      "TimeHistory: 1.52 seconds, 168844.16 examples/second between steps 133000 and 133500\n",
      "TimeHistory: 1.62 seconds, 158504.71 examples/second between steps 133500 and 134000\n",
      "TimeHistory: 1.75 seconds, 145905.61 examples/second between steps 134000 and 134500\n",
      "TimeHistory: 1.72 seconds, 149268.26 examples/second between steps 134500 and 135000\n",
      "TimeHistory: 1.77 seconds, 144538.36 examples/second between steps 135000 and 135500\n",
      "TimeHistory: 1.54 seconds, 166359.40 examples/second between steps 135500 and 136000\n",
      "TimeHistory: 1.83 seconds, 140021.22 examples/second between steps 136000 and 136500\n",
      "TimeHistory: 1.50 seconds, 170402.32 examples/second between steps 136500 and 137000\n",
      "TimeHistory: 1.49 seconds, 171559.91 examples/second between steps 137000 and 137500\n",
      "TimeHistory: 1.49 seconds, 171240.42 examples/second between steps 137500 and 138000\n",
      "TimeHistory: 1.49 seconds, 171751.34 examples/second between steps 138000 and 138500\n",
      "TimeHistory: 1.48 seconds, 172399.05 examples/second between steps 138500 and 139000\n",
      "global_steps: 139194, last_log_step: 139000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13289\n",
      "3750605/3750605 - 75s - loss: 0.1903 - accuracy: 0.9211 - val_loss: 0.1558 - val_accuracy: 0.9399\n",
      "Epoch 20/20\n",
      "TimeHistory: 53.80 seconds, 4758.51 examples/second between steps 139000 and 139500\n",
      "TimeHistory: 1.69 seconds, 151291.29 examples/second between steps 139500 and 140000\n",
      "TimeHistory: 1.64 seconds, 156511.16 examples/second between steps 140000 and 140500\n",
      "TimeHistory: 1.90 seconds, 134984.30 examples/second between steps 140500 and 141000\n",
      "TimeHistory: 1.61 seconds, 158525.91 examples/second between steps 141000 and 141500\n",
      "TimeHistory: 1.80 seconds, 141909.06 examples/second between steps 141500 and 142000\n",
      "TimeHistory: 1.59 seconds, 161001.74 examples/second between steps 142000 and 142500\n",
      "TimeHistory: 1.78 seconds, 143904.23 examples/second between steps 142500 and 143000\n",
      "TimeHistory: 1.89 seconds, 135459.91 examples/second between steps 143000 and 143500\n",
      "TimeHistory: 1.62 seconds, 157544.56 examples/second between steps 143500 and 144000\n",
      "TimeHistory: 1.58 seconds, 162494.27 examples/second between steps 144000 and 144500\n",
      "TimeHistory: 1.58 seconds, 161781.61 examples/second between steps 144500 and 145000\n",
      "TimeHistory: 1.83 seconds, 139745.25 examples/second between steps 145000 and 145500\n",
      "TimeHistory: 1.82 seconds, 140711.84 examples/second between steps 145500 and 146000\n",
      "TimeHistory: 1.66 seconds, 154203.19 examples/second between steps 146000 and 146500\n",
      "global_steps: 146520, last_log_step: 146500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13289\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "3750605/3750605 - 75s - loss: 0.1891 - accuracy: 0.9215 - val_loss: 0.1576 - val_accuracy: 0.9392\n"
     ]
    }
   ],
   "source": [
    "hist = ncf.fit(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    path_model_weights='/Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf-weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5',\n",
    "    path_csvlog='/Users/xyin/Documents/work/projects/rec_utils/metadata/ncf5/ncf_log.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to load the parameters from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.model.load_weights('../metadata/ncf5/ncf-weights-improvement-12-0.1329.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf.model.save('../metadata/ncf5/ncf-best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25252525, 25252525)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.users_test), len(dataset.items_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3660)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset.users_test)), len(set(dataset.items_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.ratings_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0   171     1.0\n",
       "1     0   110     0.0\n",
       "2     0  2994     0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_true = pd.DataFrame({\n",
    "    'user':dataset.users_test,\n",
    "    'item':dataset.items_test,\n",
    "    'rating':dataset.ratings_test\n",
    "})\n",
    "rating_true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25252525, 3), (250025, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_true.shape, rating_true[rating_true.rating>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 6s, sys: 1min 17s, total: 11min 24s\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "list_preds = ncf.model.predict(\n",
    "        x=[\n",
    "            np.array(dataset.users_test),\n",
    "            np.array(dataset.items_test)\n",
    "        ]\n",
    "    ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25252525"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0.932909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0.931356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2994</td>\n",
       "      <td>0.016190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item    rating\n",
       "0     0   171  0.932909\n",
       "1     0   110  0.931356\n",
       "2     0  2994  0.016190"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_pred = pd.DataFrame({\n",
    "    'user':dataset.users_test,\n",
    "    'item':dataset.items_test,\n",
    "    'rating':list_preds\n",
    "})\n",
    "rating_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_pred = rating_pred.rename(columns={'rating':'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.7 s, sys: 6.16 s, total: 49.8 s\n",
      "Wall time: 50.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ndcg = evaluation.ndcg_at_k(\n",
    "    rating_true.loc[rating_true.rating>0],\n",
    "    rating_pred,\n",
    "    col_user='user',\n",
    "    col_item='item',\n",
    "    col_rating='rating',\n",
    "    col_pred='prediction',\n",
    "    k=10\n",
    ")\n",
    "\n",
    "recall = evaluation.recall_at_k(\n",
    "    rating_true.loc[rating_true.rating>0],\n",
    "    rating_pred,\n",
    "    col_user='user',\n",
    "    col_item='item',\n",
    "    col_rating='rating',\n",
    "    col_pred='prediction',\n",
    "    k=10\n",
    ")\n",
    "\n",
    "precision = evaluation.precision_at_k(\n",
    "    rating_true.loc[rating_true.rating>0],\n",
    "    rating_pred,\n",
    "    col_user='user',\n",
    "    col_item='item',\n",
    "    col_rating='rating',\n",
    "    col_pred='prediction',\n",
    "    k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18303133620423187, 0.10581144589480436, 0.15637417218543048)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
