{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the NCF modules under folder [cf_ec2](../cf_ec2) with ml-1m dataset, save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import (\n",
    "    Adam,\n",
    "    Adamax,\n",
    "    Adagrad,\n",
    "    SGD,\n",
    "    RMSprop\n",
    ")\n",
    "from keras.layers import (\n",
    "    Embedding, \n",
    "    Input,\n",
    "    Flatten, \n",
    "    Multiply, \n",
    "    Concatenate,\n",
    "    Dense\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cf_ec2 import (\n",
    "    GMF,\n",
    "    MLP,\n",
    "    NCF,\n",
    "    Data,\n",
    "    evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/ml-1m.train.rating',sep='\\t',header=None,names=['user','item','rating','event_ts'])\n",
    "test = pd.read_csv('../data/ml-1m.test.rating',sep='\\t',header=None,names=['user','item','rating','event_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>event_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   event_ts\n",
       "0     0    32       4  978824330\n",
       "1     0    34       4  978824330\n",
       "2     0     4       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>event_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   event_ts\n",
       "0     0    25       5  978824351\n",
       "1     1   133       3  978300174\n",
       "2     2   207       4  978298504"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, (6040, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.user.nunique(), test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: prepare the data for ncf model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    col_user='user',\n",
    "    col_item='item',\n",
    "    col_rating='rating',\n",
    "    col_time='event_ts',\n",
    "    binary=True,\n",
    "    n_neg=4,\n",
    "    n_neg_test=100\n",
    ")\n",
    "dataset.prepTrainDNN()\n",
    "dataset.prepTestDNN()\n",
    "dataset.negativeSampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4970845, (994169, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.users),train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610040, (6040, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.users_test),test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 6040)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.user.nunique(), test.user.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3704, 1921)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item.nunique(), test.item.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item_interacted</th>\n",
       "      <th>item_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>{52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{15, 22, 31, 34, 35, 42, 43, 52, 53, 54, 55, 5...</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{2, 135, 136, 14, 18, 147, 159, 163, 36, 40, 1...</td>\n",
       "      <td>{0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                    item_interacted  \\\n",
       "0     0  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1     1  {15, 22, 31, 34, 35, 42, 43, 52, 53, 54, 55, 5...   \n",
       "2     2  {2, 135, 136, 14, 18, 147, 159, 163, 36, 40, 1...   \n",
       "\n",
       "                                       item_negative  \n",
       "0  {52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 6...  \n",
       "1  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "2  {0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.interaction_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3704)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset.users)), len(set(dataset.items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset.users_test)), len(set(dataset.items_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newItems = set(dataset.items_test)-set(dataset.items)\n",
    "idx2del = []\n",
    "for idx,item in enumerate(dataset.items_test):\n",
    "    if item in newItems:\n",
    "        idx2del.append(idx)\n",
    "\n",
    "length_test_original = len(dataset.users_test)\n",
    "dataset.users_test = [\n",
    "    dataset.users_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]\n",
    "dataset.items_test = [\n",
    "    dataset.items_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]\n",
    "dataset.ratings_test = [\n",
    "    dataset.ratings_test[idx]\n",
    "    for idx in range(length_test_original) if idx not in idx2del\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: create the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1210 12:22:32.945915 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1210 12:22:32.971755 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1210 12:22:33.030456 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1210 12:22:33.069296 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1210 12:22:33.081480 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1210 12:22:33.085872 4402009536 deprecation_wrapper.py:119] From /anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1210 12:22:33.089789 4402009536 deprecation.py:323] From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "n_users = 6040\n",
    "n_items = 3704\n",
    "n_factors_gmf = 32\n",
    "layers_mlp = [64,32,16,8]\n",
    "reg_gmf = 0.\n",
    "reg_layers_mlp = [0.,0.,0.,0.]\n",
    "learning_rate = 0.01\n",
    "flg_pretrain = ''\n",
    "filepath = ''\n",
    "filepath_gmf_pretrain = ''\n",
    "filepath_mlp_pretrain = ''\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "ncf = NCF(\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    n_factors_gmf=n_factors_gmf,\n",
    "    layers_mlp=layers_mlp,\n",
    "    reg_gmf=reg_gmf,\n",
    "    reg_layers_mlp=reg_layers_mlp\n",
    ")\n",
    "model = ncf.create_model()\n",
    "#### compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=learning_rate),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "#### create the callback metrics\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath= '../metadata/ncf/ncf_model_best', \n",
    "    verbose=1, \n",
    "    save_best_only=True\n",
    ")\n",
    "csvlog = keras.callbacks.CSVLogger(\n",
    "    '../metadata/ncf/ncf_log.csv', \n",
    "    separator=',', \n",
    "    append=False\n",
    ")\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=12)\n",
    "lrreduce = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", \n",
    "    factor=0.3, \n",
    "    patience=4, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4970845 samples, validate on 610038 samples\n",
      "Epoch 1/20\n",
      " - 236s - loss: 0.3471 - acc: 0.8410 - val_loss: 0.1914 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19142, saving model to ../metadata/ncf/ncf_model_best\n",
      "Epoch 2/20\n",
      " - 227s - loss: 0.3166 - acc: 0.8582 - val_loss: 0.2030 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19142\n",
      "Epoch 3/20\n",
      " - 235s - loss: 0.3121 - acc: 0.8618 - val_loss: 0.1759 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19142 to 0.17587, saving model to ../metadata/ncf/ncf_model_best\n",
      "Epoch 4/20\n",
      " - 229s - loss: 0.3064 - acc: 0.8668 - val_loss: 0.1885 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17587\n",
      "Epoch 5/20\n",
      " - 245s - loss: 0.3054 - acc: 0.8688 - val_loss: 0.2051 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17587\n",
      "Epoch 6/20\n",
      " - 249s - loss: 0.3056 - acc: 0.8704 - val_loss: 0.1262 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17587 to 0.12620, saving model to ../metadata/ncf/ncf_model_best\n",
      "Epoch 7/20\n",
      " - 240s - loss: 0.3046 - acc: 0.8728 - val_loss: 0.1579 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12620\n",
      "Epoch 8/20\n",
      " - 252s - loss: 0.3038 - acc: 0.8746 - val_loss: 0.2088 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12620\n",
      "Epoch 9/20\n",
      " - 243s - loss: 0.3037 - acc: 0.8762 - val_loss: 0.1612 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12620\n",
      "Epoch 10/20\n",
      " - 242s - loss: 0.3036 - acc: 0.8775 - val_loss: 0.2057 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12620\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
      "Epoch 11/20\n",
      " - 229s - loss: 0.2589 - acc: 0.8923 - val_loss: 0.1590 - val_acc: 0.9320\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12620\n",
      "Epoch 12/20\n",
      " - 228s - loss: 0.2530 - acc: 0.8951 - val_loss: 0.1515 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12620\n",
      "Epoch 13/20\n",
      " - 251s - loss: 0.2494 - acc: 0.8972 - val_loss: 0.1601 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12620\n",
      "Epoch 14/20\n",
      " - 257s - loss: 0.2456 - acc: 0.8990 - val_loss: 0.1783 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12620\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
      "Epoch 15/20\n",
      " - 259s - loss: 0.2239 - acc: 0.9080 - val_loss: 0.1640 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12620\n",
      "Epoch 16/20\n",
      " - 267s - loss: 0.2217 - acc: 0.9091 - val_loss: 0.1657 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12620\n",
      "Epoch 17/20\n",
      " - 261s - loss: 0.2201 - acc: 0.9098 - val_loss: 0.1659 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12620\n",
      "Epoch 18/20\n",
      " - 263s - loss: 0.2187 - acc: 0.9105 - val_loss: 0.1555 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12620\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n"
     ]
    }
   ],
   "source": [
    "#### train\n",
    "hist = model.fit(\n",
    "    x = [\n",
    "        np.array(dataset.users),\n",
    "        np.array(dataset.items)\n",
    "    ],\n",
    "    y = np.array(dataset.ratings),\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint,csvlog,earlystop,lrreduce],\n",
    "    validation_data=[\n",
    "        [np.array(dataset.users_test),np.array(dataset.items_test)],\n",
    "        np.array(dataset.ratings_test)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.19141636139927704,\n",
       "  0.20298453419919416,\n",
       "  0.17587084039748271,\n",
       "  0.18854073413501876,\n",
       "  0.20513475767298153,\n",
       "  0.1262007889407188,\n",
       "  0.15794206839426292,\n",
       "  0.20882419177667863,\n",
       "  0.16121499948453813,\n",
       "  0.2056902889382691,\n",
       "  0.15903311647938065,\n",
       "  0.15154774740219953,\n",
       "  0.1601451641549566,\n",
       "  0.17826030145408625,\n",
       "  0.16404884681243623,\n",
       "  0.16573054983249905,\n",
       "  0.16591598149803244,\n",
       "  0.15554556764649174],\n",
       " 'val_acc': [0.929022456397194,\n",
       "  0.9179887170655134,\n",
       "  0.9246227296610686,\n",
       "  0.919778769265511,\n",
       "  0.911733369180274,\n",
       "  0.9486507422005938,\n",
       "  0.9317780216616615,\n",
       "  0.9074074084178875,\n",
       "  0.9314354208890181,\n",
       "  0.9122612052019553,\n",
       "  0.9319993196483413,\n",
       "  0.9358794061223048,\n",
       "  0.9324599467023853,\n",
       "  0.9244391350588043,\n",
       "  0.9314370600486994,\n",
       "  0.9304141729217235,\n",
       "  0.9313813254221884,\n",
       "  0.9364154384776286],\n",
       " 'loss': [0.34709987770233347,\n",
       "  0.3165626227382344,\n",
       "  0.3121344553044487,\n",
       "  0.30639764288683735,\n",
       "  0.3054343348763331,\n",
       "  0.3056224581690873,\n",
       "  0.3045794017037246,\n",
       "  0.30384743001439546,\n",
       "  0.3036626052772941,\n",
       "  0.30355118996019503,\n",
       "  0.25890183824704577,\n",
       "  0.2529971132025583,\n",
       "  0.24936414809152593,\n",
       "  0.24556041249145566,\n",
       "  0.22391110332242767,\n",
       "  0.22167389254961334,\n",
       "  0.22007316568636723,\n",
       "  0.21869504439558515],\n",
       " 'acc': [0.8409948395243526,\n",
       "  0.8581911118105978,\n",
       "  0.8617679684119685,\n",
       "  0.8667745621919157,\n",
       "  0.868778245828917,\n",
       "  0.870406540195166,\n",
       "  0.8728099547471512,\n",
       "  0.8746020042230743,\n",
       "  0.8761783962147742,\n",
       "  0.8774997006898728,\n",
       "  0.8923104630170376,\n",
       "  0.8950570786064133,\n",
       "  0.8971689934295473,\n",
       "  0.8990304476547506,\n",
       "  0.9080196641775056,\n",
       "  0.9090530900746492,\n",
       "  0.9097960222721765,\n",
       "  0.9104910751098353],\n",
       " 'lr': [0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.01,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.0009,\n",
       "  0.0009,\n",
       "  0.0009,\n",
       "  0.0009]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
